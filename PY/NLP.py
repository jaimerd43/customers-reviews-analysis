# -*- coding: utf-8 -*-
"""Assignment2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1yOD2Res_EY5Vy6HhxT3QTV4JVube3coy
"""

import pandas as pd
import pandas as pd
import numpy as np
import re
import seaborn as sns
import matplotlib.pyplot as plt

import nltk
nltk.download('punkt')
from nltk.corpus import stopwords
nltk.download('stopwords')
from nltk.stem import WordNetLemmatizer
nltk.download('wordnet')
from nltk.tokenize import word_tokenize

from nltk.stem import PorterStemmer

from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.linear_model import SGDClassifier
from sklearn.metrics import f1_score
from sklearn.model_selection import train_test_split
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import FunctionTransformer
from sklearn.semi_supervised import SelfTrainingClassifier
from sklearn.metrics import confusion_matrix, accuracy_score, classification_report
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC

from google.colab import drive
drive.mount('/content/drive')

path = '/content/drive/MyDrive/A_II_Emotion_Data_Student_Copy_Final.xlsx'
data1 = pd.read_excel(path)

data1.info()

"""Data preprocessing"""

pip install langdetect

#remove special characteres from the reviews
def clean_text1(text):
    text = re.sub(r'http\S+', '', text)
    text = re.sub(r'<[^>]+>', '', text)
    text = re.sub(r'[^a-zA-Z\s]', '', text)
    return text

data1['text_reviews_1'] = data1['text_reviews_'].apply(clean_text1)

#detecte languages in the reviews
from langdetect import detect, LangDetectException

def detectar_idioma(texto):
    try:
        return detect(texto)
    except LangDetectException:
        return "unknown"

data1["language"] = data1['text_reviews_1'].apply(detectar_idioma)
df_no_ingles = data1[data1['language'] != 'en']

total_en = (data1["language"] == "en").sum()

total_en

#plot distribution of languages
language_counts = data1['language'].value_counts()

plt.figure(figsize=(4, 2))
plt.bar(language_counts.index, language_counts.values, color='skyblue', edgecolor='black')
plt.xlabel('Language')
plt.ylabel('Number of Reviews')
plt.title('Language Distribution Accross the reviews')
plt.xticks(rotation=90, fontweight='bold')
plt.show()

#delete from the data set with no english reviews those reviews from GB to reduce the size of it
df_no_ingles1 = df_no_ingles[df_no_ingles['country_'] != 'GB']

df_no_ingles1 = df_no_ingles1.copy()

df_no_ingles1.loc[:, 'longitud'] = df_no_ingles1['text_reviews_1'].str.len()


total_caracteres = df_no_ingles1['longitud'].sum()

total_caracteres

# API deepl only allows 500000 for free, so the data set is divide and Baidu is also used
df_no_ingles1 = df_no_ingles1.copy()

df_no_ingles1.loc[:, 'length'] = df_no_ingles1['text_reviews_1'].str.len()
df_no_ingles1.loc[:, 'cumulative_length'] = df_no_ingles1['length'].cumsum()

df_filtered = df_no_ingles1[df_no_ingles1['cumulative_length'] <= 500000]
df_filtered2 = df_no_ingles1[df_no_ingles1['cumulative_length'] > 500000]

#Translate the others 400000 characteres
import requests
from hashlib import md5
import random
import json
appid = '20240402002013298'
appkey = 'BRdzUuBl3BBAMC9es1d8'

def make_md5(s, encoding='utf-8'):
    return md5(s.encode(encoding)).hexdigest()

def baidu_api(query, from_lang='auto', to_lang='en'):
    endpoint = 'http://api.fanyi.baidu.com'
    path = '/api/trans/vip/translate'
    url = f"{endpoint}{path}"
    salt = random.randint(32768, 65536)
    sign = make_md5(appid + query + str(salt) + appkey)
    headers = {'Content-Type': 'application/x-www-form-urlencoded'}
    payload = {
        'appid': appid,
        'q': query,
        'from': from_lang,
        'to': to_lang,
        'salt': salt,
        'sign': sign
    }

    try:
        r = requests.post(url, params=payload, headers=headers, timeout=10)
        result = r.json()
        if 'error_code' in result:
            print(f"Error {result['error_code']}: {result.get('error_msg', 'No error message')}")
            return query
        return result["trans_result"][0]['dst']
    except Exception as e:
        print(f"Error during translation: {e}")
        return query

def translate_text(text):
    return baidu_api(text, from_lang='auto', to_lang='en')

df_filtered2['translated_text'] = df_filtered2['text_reviews_1'].apply(translate_text)

#Translate the first 500000 characteres
import deepl

translator = deepl.Translator("ee87c8a8-fe26-4956-a1d6-bbe41f8590f1:fx")

def translate_text(text):
    try:
        result = translator.translate_text(text, target_lang="EN-GB")
        return result.text
    except Exception as e:
        print(f"Error al traducir el texto: {e}")
        return text

df_filtered['translated_text'] = df_filtered['text_reviews_1'].apply(translate_text)

#adding the Deepl translated reviews to the original data set
result_df = pd.merge(data, df_filtered[['ID_', 'translated_text']], on='ID_', how='left')

result_df['text_reviews_'] = result_df['translated_text'].combine_first(result_df['text_reviews_'])

result_df.drop(['translated_text','text_reviews_1', 'language'], axis=1, inplace=True)

#adding the Baidu translated reviews to the previous data set
merged_df = pd.merge(result_df, df_filtered2[['ID_', 'translated_text']], on='ID_', how='left')

merged_df['text_reviews_'] = merged_df['translated_text'].combine_first(merged_df['text_reviews_'])

final_df = merged_df.drop('translated_text', axis=1)

final_df.drop('Cleaned_reviews', axis=1, inplace=True)

"""New file with all the reviews in English"""

path = '/content/drive/MyDrive/final_reviews.csv'
data = pd.read_csv(path)

data.info()

#remove 2 missing values originated when the reviews were translated
data = data.dropna(subset=['text_reviews_'])

pip install langdetect

#plot language distribution accross reviews
from langdetect import detect, LangDetectException

def detectar_idioma(texto):
    try:
        return detect(texto)
    except LangDetectException:
        return "unknown"

to_plot = data.copy()

to_plot["language"] = to_plot['text_reviews_'].apply(detectar_idioma)

language_counts = to_plot['language'].value_counts()

plt.figure(figsize=(6, 4))
plt.bar(language_counts.index, language_counts.values, color='skyblue', edgecolor='black')
plt.xlabel('Language')
plt.ylabel('Number of Reviews')
plt.title('Language Distribution Accross the translated reviews')
plt.xticks(rotation=90)
plt.show()

"""Text Data Pre-Processing"""

# function to do text pre-processing
def clean_text(text):
    text = re.sub(r'http\S+', '', text)  # Remove URLs
    text = re.sub(r'<[^>]+>', '', text)  # Remove HTML tags
    text = text.lower()  # Lowercase text
    text = re.sub(r'\b\w{1,2}\b', '', text)  # Remove words with 1 or 2 letters
    text = re.sub(r'[^a-z\s]', '', text)  # Keep text with letters and spaces

    # Tokenize
    tokens = word_tokenize(text)

    # Remove stopwords
    stop_words = set(stopwords.words('english'))
    tokens = [word for word in tokens if word not in stop_words]

    # Lemmatize 0.56
    lemmatizer = WordNetLemmatizer()
    tokens = [lemmatizer.lemmatize(word) for word in tokens]

    # Stemming 0.54
    #stemmer = PorterStemmer()
    #tokens = [stemmer.stem(word) for word in tokens]

    return ' '.join(tokens)

# new column is created with the clean text
data['Cleaned_reviews'] = data['text_reviews_'].apply(clean_text)

"""Initial descriptive analysis"""

sns.set(style="whitegrid")
plt.figure(figsize=(8, 8))

top_countries = data['country_'].value_counts().head(15).index
# Filtering the data to include only the top 15 countries
filtered_data = data[data['country_'].isin(top_countries)]
missing_emotions = data['emotions_'].isnull().sum()

# Adjusting the categorical columns to use the filtered data for country_
categorical_columns = ['brand_name_', 'country_', 'emotions_']
numerical_columns = ['star_rating_']

rows, cols = 2, 2

for index, column in enumerate(categorical_columns):
    plt.subplot(rows, cols, index + 1)
    # Ensure the plotting is done on 'filtered_data' for the 'country_' column
    if column == 'country_':
        sns.countplot(y=column, data=filtered_data, palette="Set2")
    else:
        count_plot = sns.countplot(y=column, data=data, palette="Set2")
    plt.title(f'{column}', fontweight='bold')
    plt.tight_layout()


    if column == 'emotions_':
        plt.text(count_plot.get_xlim()[1], count_plot.get_ylim()[0], f'Missing Values: {missing_emotions}',
                 horizontalalignment='left', verticalalignment='top',
                 fontsize=12, color='red')

plt.subplot(rows, cols, len(categorical_columns) + 1)
sns.violinplot(y='star_rating_', data=data, color="skyblue")
plt.title('star_rating_', fontweight='bold')
plt.tight_layout()

plt.show()

"""Machine Learning

Unlabeled data
"""

# data frame is created with missing observations of emotions (Unlabeled data) and Cleaned reviwes is included in the data frame.
unlabeled_data = data[pd.isna(data['emotions_'])][['Cleaned_reviews']]
unlabeled_data['emotions_'] = -1

"""Labeled Data"""

# data frame is created with known observations of emotions (Labeled data) and Cleaned reviwes is included in the data frame.
labeled_data = data[data['emotions_'].notna()][['Cleaned_reviews', 'emotions_']]

"""Create X and y"""

X = data['Cleaned_reviews']
y = data['emotions_']

# known emotions
y_labeled = labeled_data['emotions_']
# missing emotions
y_unlabeled = unlabeled_data['emotions_']
# cleaned reviews for known emotions
X_labeled = labeled_data['Cleaned_reviews']
# cleaned reviews for missing emotions
X_unlabeled = unlabeled_data['Cleaned_reviews']

"""Function for calssification report"""

# Commented out IPython magic to ensure Python compatibility.
def eval_and_print_metrics(clf, X_train, y_train, X_test, y_test):
    print("Number of training samples:", len(X_train))
    print("Unlabeled samples in training set:", sum(1 for x in y_train if x == -1)) #if x == 'NaN'
    clf.fit(X_train, y_train)
    y_pred = clf.predict(X_test)

    print(
        "Micro-averaged F1 score on test set: %0.3f"
#         % f1_score(y_test, y_pred, average="micro")
    )
    print("\nConfusion Matrix:\n", confusion_matrix(y_test,y_pred))
    print("\nClassification Report:\n", classification_report(y_test, y_pred,zero_division=1))
    print("\n\n")

"""Split the labeled data"""

X_train, X_test, y_train, y_test = train_test_split(X_labeled, y_labeled, test_size=0.2, stratify=y_labeled, random_state=42)

from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import GridSearchCV

"""TfidfVectorizer"""

pip install mglearn

import mglearn

def visualize_coefficients_multiclass_modified(coef_matrix, feature_names, class_labels, n_top_features=40):
    """
    Visualiza los coeficientes más importantes para cada clase, con los nombres de las clases en los títulos.

    :param coef_matrix: Matriz de coeficientes (clases x características).
    :param feature_names: Nombres de las características.
    :param class_labels: Etiquetas de las clases.
    :param n_top_features: Número de características más importantes para mostrar.
    """
    n_classes = coef_matrix.shape[0]

    for i in range(n_classes):
        plt.figure(figsize=(15, 5))
        coef = coef_matrix[i, :]
        mglearn.tools.visualize_coefficients(coef, feature_names, n_top_features)
        plt.title(f"Clase {class_labels[i]}")  # Usar las etiquetas de clase reales para el título
        plt.show()

# Suponiendo que tienes un modelo llamado 'grid' que ya ha sido entrenado
class_labels = grid.best_estimator_.named_steps["logisticregression"].classes_
coeficientes = grid.best_estimator_.named_steps["logisticregression"].coef_
# Asegúrate de que 'feature_names' contiene los nombres de las características de tu modelo

# Ahora, llama a la función modificada con los nombres de las clases
visualize_coefficients_multiclass_modified(coeficientes, feature_names, class_labels, n_top_features=40)

"""BARD WORDS"""

pip install mglearn

import mglearn
pipe1 = make_pipeline(TfidfVectorizer(), LogisticRegression(max_iter=10000))

#Source: (Bird, S., Klein, E. and Loper, E. (2009) Natural language processing with python. Bejing: O’Reilly.)

#set parameter of logistic reression (C), based on previous calculation it is known that we required a high value for C
param_grid1 = {
    "logisticregression__C": [10, 100],
    "tfidfvectorizer__ngram_range": [(1, 1), (1, 2), (1, 3)],
    "tfidfvectorizer__max_features": [1000, 2000, 3000, 5000]
}

grid1 = GridSearchCV(pipe1, param_grid1, cv=5)
grid1.fit(X_train, y_train)

scores = grid1.cv_results_['mean_test_score'].reshape(len(param_grid1["logisticregression__C"]),
                                                       len(param_grid1["tfidfvectorizer__ngram_range"]),
                                                       len(param_grid1["tfidfvectorizer__max_features"]))
scores_mean = scores.mean(axis=0)

heatmap = mglearn.tools.heatmap(scores_mean, xlabel="max_features", ylabel="ngram_range", cmap="viridis", fmt="%.3f",
                                xticklabels=param_grid1["tfidfvectorizer__max_features"],
                                yticklabels=param_grid1["tfidfvectorizer__ngram_range"])

plt.colorbar(heatmap)
plt.show()

"""best ngram (1,1) por lo tanto la visualizacion y la agrupacion es igual que antes

**Supervised Machine learning** model for labelated data
"""

from sklearn.model_selection import GridSearchCV
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer
from sklearn.ensemble import RandomForestClassifier
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.linear_model import SGDClassifier
from sklearn.naive_bayes import MultinomialNB

vectorizer_params = {
    'ngram_range': (1, 2),
    'max_features': 3000
}

#hyper parameter tuning

param_grid = {
    "Random Forest": {
        "clf__n_estimators": [50, 100, 200],
        "clf__max_depth": [None, 10, 20, 30],
        "clf__min_samples_split": [2, 5, 10]
    },
    "K-Nearest Neighbors": {
        "clf__n_neighbors": [3, 5, 6, 7],
        "clf__weights": ["uniform", "distance"],
        "clf__algorithm": ["auto", "ball_tree"]
    },
    "Support Vector Machine": {
        "clf__C": [0.1, 1, 10],
        "clf__kernel": ["linear", "rbf", "poly"]
    },
    "SDG": {
        "clf__alpha": [1e-5, 1e-4, 1e-3],
        "clf__penalty": ["l2", "l1"],
        "clf__loss": ["hinge", "log"]
    },
    "Naive Bayes": {
        "clf__alpha": [0.01, 0.1, 1.0]
    }
}


supervised_classifiers = [
    ("Random Forest", RandomForestClassifier(), param_grid["Random Forest"]),
    ("K-Nearest Neighbors", KNeighborsClassifier(), param_grid["K-Nearest Neighbors"]),
    ("Support Vector Machine", SVC(), param_grid["Support Vector Machine"]),
    ("SDG", SGDClassifier(), param_grid["SDG"]),
    ("Naive Bayes", MultinomialNB(), param_grid["Naive Bayes"])
]



classifier_names = []
accuracy_scores = []

for name, clf, params in supervised_classifiers:
    pipeline = Pipeline([
        ("vect", TfidfVectorizer(**vectorizer_params)),
        ("clf", clf),
    ])
    grid_search = GridSearchCV(pipeline, param_grid=params, n_jobs=-1, cv=10)
    grid_search.fit(X_labeled, y_labeled)
    best_clf = grid_search.best_estimator_
    best_params = grid_search.best_params_
    best_score = grid_search.best_score_

    # Print best hyperparameters
    print(f"Best Hyperparameters for {name}: {best_params}")

    # Evaluate and print metrics
    eval_and_print_metrics(best_clf, X_train, y_train, X_test, y_test)

    # Store the name and the accuracy for plotting
    classifier_names.append(name)
    accuracy_scores.append(best_score)

classifier_names = ["RF", "K-NN", "SVM", "SDG", "MNB"]

# Plotting the accuracies
plt.figure(figsize=(4, 3))
plt.bar(classifier_names, accuracy_scores, color='blue')
plt.title('Cross-validataion Classifiers Accuracies')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

print("Classification Report:")
print(classification_report(y_test, y_pred1))

best_params_sdg = { 'alpha': 0.001,'loss': 'log',
    'penalty': 'l1'}

pipeline_sdg = Pipeline([
    ("vect", TfidfVectorizer(**vectorizer_params)),
    ("clf", SGDClassifier(**best_params_sdg))
])

pipeline_sdg.fit(X_train, y_train)

y_pred1 = pipeline_sdg.predict(X_test)

cm = confusion_matrix(y_test, y_pred1)
plt.figure(figsize=(4,4))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

test_indices = X_test.index

# Exclude test data from X_labeled and y_labeled based on the identified indices
X_labeled_filtered = X_labeled.drop(index=test_indices, errors='ignore')
y_labeled_filtered = y_labeled.drop(index=test_indices, errors='ignore')

# Concatenate the filtered labeled data with the unlabeled data
# lop que se esta haciendo es extraer de X labeled e y labeled el test data test (me quedo con el train)
# se junta train labeled con toda la unlabeled por lo tanto tengo: X = x train label + all unlabeled. Y = y train labeled + all unlabeled
# x_test y y_test es todo labeled data para comprobar accuracy de las predicciones
X=X_combined = pd.concat([X_labeled_filtered, X_unlabeled])
y=y_combined = pd.concat([y_labeled_filtered, y_unlabeled])

# Define the mapping for labels
label_mapping = {
    'anger': 0,
    'disgust': 1,
    'fear': 2,
    'joy': 3,
    'neutral': 4,
    'sadness': 5,
    'surprise': 6, -1:-1}

# Apply the mapping to labels
y  = [label_mapping[label] for label in y]
print(y)
y_test  = [label_mapping[label] for label in y_test]
print(y_test)

from sklearn.linear_model import LogisticRegression, SGDClassifier
from sklearn.naive_bayes import MultinomialNB
from sklearn.tree import DecisionTreeClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.semi_supervised import SelfTrainingClassifier

vectorizer_params = {
    'ngram_range': (1, 2),
    'max_features': 3000
}

random_state_seed = 40425150

# Defining classfiers with the best hyperparameter of supervised
non_graph_based_classifiers = [
    ("SelfTraining Logistic Regression", SelfTrainingClassifier(LogisticRegression(max_iter=1000), criterion='threshold', threshold=0.9)),
    ("SelfTraining K-Nearest Neighbors", SelfTrainingClassifier(base_estimator=KNeighborsClassifier(n_neighbors=7, algorithm='auto', weights='distance'))),
    ("SelfTraining Naive Bayes", SelfTrainingClassifier(MultinomialNB())),
    ("SelfTraining SVC linear", SelfTrainingClassifier(SVC(probability=True, C=10, gamma='scale', kernel='linear'), criterion='threshold', threshold=0.9)),
    ("SelfTraining SDG", SelfTrainingClassifier(SGDClassifier(alpha=0.001, loss='log', penalty='l1'), verbose = True)),
    ("Random Forest", SelfTrainingClassifier(RandomForestClassifier(max_depth=20, min_samples_split=10, n_estimators=200)))
]


for name, clf in non_graph_based_classifiers:
    print(f"Evaluating {name}")
    st_pipeline = Pipeline([
        ("vect", TfidfVectorizer(**vectorizer_params)),
        ("clf", clf),
    ])
    eval_and_print_metrics(st_pipeline, X, y, X_test, y_test)

from sklearn.semi_supervised import LabelSpreading

vectorizer_params = {
    'ngram_range': (1, 2),
    'max_features': 3000
}

ls_pipeline = Pipeline(
    [
        ("vect", TfidfVectorizer(**vectorizer_params)),
        ("toarray", FunctionTransformer(lambda x: x.toarray())),
        ("clf", LabelSpreading()),
    ]
)
ls_pipeline.fit(X, y)

eval_and_print_metrics(ls_pipeline, X, y, X_test, y_test)

"""Best performance is Random Forest"""

X_unlabeled

st_svc_pipeline = Pipeline([
    ("vect", TfidfVectorizer(**vectorizer_params)),
    ("SelfTraining SGD", SelfTrainingClassifier(SGDClassifier(alpha=0.001, loss='log', penalty='l1'), verbose = True))])

st_svc_pipeline.fit(X, y)

y_pred2 = st_svc_pipeline.predict(X_test)

print("Classification Report:")
print(classification_report(y_test, y_pred2))

cm2 = confusion_matrix(y_test, y_pred2)
plt.figure(figsize=(4,4))
sns.heatmap(cm2, annot=True, fmt="d", cmap="Blues", cbar=False)
plt.title("Confusion Matrix")
plt.xlabel("Predicted Label")
plt.ylabel("True Label")
plt.show()

"""Predicting with the supervised model"""

predictions = st_svc_pipeline.predict(X_unlabeled)

plt.hist(predictions, bins='auto', color='skyblue', edgecolor='black')
plt.title('Distribution of Predictions')
plt.xlabel('Predicted Label')
plt.ylabel('Frequency')
plt.show()

data1 = data.copy()

inverse_label_mapping = {v: k for k, v in label_mapping.items()}

text_predictions = np.array([inverse_label_mapping[pred] for pred in predictions])

missing_emotion_indices = data1[data1['emotions_'].isna()].index

assert len(predictions) == len(missing_emotion_indices)

data1.loc[missing_emotion_indices, 'emotions_'] = text_predictions

data1.info()

plt.hist(data1['emotions_'], bins='auto', color='skyblue', edgecolor='black')
figsize=(7, 7)
plt.title('Distribution of Predictions')
plt.xlabel('Predicted Label')
plt.ylabel('Frequency')
plt.xticks(fontweight = "bold")
plt.show()

"""ANALYSIS OF BRAND"""

import seaborn as sns
import matplotlib.pyplot as plt

# Establecer el estilo de los gráficos
sns.set(style="whitegrid")

# Gráfico de conteo de emociones por marca
plt.figure(figsize=(4, 3))
sns.countplot(y='emotions_', hue='brand_name_', data=data1, palette='Set2')
plt.title('Distribution of emotions by brand')
plt.xlabel('Frequency')
plt.ylabel('Emotions')
plt.legend(title='Brand')
plt.tight_layout()
plt.show()

total_emotions_per_brand = data1.groupby('brand_name_').size().reset_index(name='total_per_brand')

# Count each emotion per brand
emotion_counts = data1.groupby(['brand_name_', 'emotions_']).size().reset_index(name='counts')

# Merge the total counts into emotion counts to calculate percentages
emotion_counts = emotion_counts.merge(total_emotions_per_brand, on='brand_name_')

# Calculate percentage
emotion_counts['percentage'] = 100 * emotion_counts['counts'] / emotion_counts['total_per_brand']

# Check the updated DataFrame
print(emotion_counts)

sns.set(style="whitegrid")

# Create a bar plot to visualize percentages
plt.figure(figsize=(4, 3))
sns.barplot(x='percentage', y='emotions_', hue='brand_name_', data=emotion_counts, palette='Set2')
plt.title('Percentage Distribution of Emotions by Brand')
plt.xlabel('Percentage')
plt.ylabel('Emotions')
plt.legend(title='Brand')
plt.tight_layout()
plt.show()

plt.figure(figsize=(6, 4))
sns.violinplot(x='star_rating_', y='brand_name_', data=data1, palette='Set3')
plt.title('Start rating by brand')
plt.xlabel('Start Rating')
plt.ylabel('Brand')
plt.tight_layout()
plt.show()

brands = data1['brand_name_'].unique()

for brand in brands:
    # Filter the dataset for the current brand
  brand_data = data1[data1['brand_name_'] == brand]
  plt.figure(figsize=(6, 4))
  sns.violinplot(x='star_rating_', y='emotions_', data=brand_data, palette='Set3')
  plt.title(f'Start rating by emotion for {brand}\n')
  plt.xlabel('Start Rating')
  plt.ylabel('Emotion')
  plt.tight_layout()
  plt.show()

# Preparar los datos
X_train, X_test, y_train, y_test = train_test_split(data1['Cleaned_reviews'], data1['emotions_'], test_size=0.2, random_state=42)

# Crear un pipeline con TF-IDF y Regresión Logística
model = make_pipeline(TfidfVectorizer(**vectorizer_params), LogisticRegression(max_iter=10000, C=10))

# Entrenar el modelo
model.fit(X_train, y_train)

# Evaluar el modelo
predictions = model.predict(X_test)
print(classification_report(y_test, predictions))

pip install mglearn

import mglearn

def visualize_coefficients_multiclass_modified(coef_matrix, feature_names, class_labels, n_top_features=20):
    n_classes = coef_matrix.shape[0]
    for i in range(n_classes):
        plt.figure(figsize=(8, 4))
        coef = coef_matrix[i, :]
        mglearn.tools.visualize_coefficients(coef, feature_names, n_top_features=n_top_features)
        plt.title(f"Emotion: {class_labels[i]}", fontsize=14, fontweight='bold')
        plt.xticks(fontsize=14, fontweight='bold')
        plt.show()

# Loop through each brand to train and evaluate a model

for brand in brands:
    # Filter the dataset for the current brand
    brand_data = data1[data1['brand_name_'] == brand]


    # Prepare the data
    X_train2, X_test2, y_train2, y_test2 = train_test_split(
        brand_data['Cleaned_reviews'], brand_data['emotions_'], test_size=0.2, random_state=42
    )

    # Create a pipeline with TF-IDF and Logistic Regression
    model = make_pipeline(TfidfVectorizer(**vectorizer_params), LogisticRegression(max_iter=10000, C=10))

    # Train the model
    model.fit(X_train2, y_train2)

    # Evaluate the model
    predictions = model.predict(X_test2)
    print(f"Classification Report for Brand: {brand}\n")
    print(classification_report(y_test2, predictions))

    # Visualization of coefficients
    vect = model.named_steps['tfidfvectorizer']
    features_names = np.array(vect.get_feature_names_out())
    coef = model.named_steps['logisticregression'].coef_
    class_labels = model.named_steps['logisticregression'].classes_
    visualize_coefficients_multiclass_modified(coef, features_names, class_labels, n_top_features=20)